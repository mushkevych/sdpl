# File generated by SDPL compiler from tests/snippet_6.sdpl
# Do not edit the file manually
# # snippet: multi-relational joins
A = sqlContext.read.csv('s3://my_bucket.s3.amazonaws.com:443/path/within/bucket/table_name', schema=StructType([ StructField('a', StringType, False),
    StructField('aa', StringType, False),
    StructField('aaa', StringType, False),
    StructField('column', BooleanType, False),
    StructField('another_column', BooleanType, False),
    StructField('yet_another_column', BooleanType, False) ])
, sep=',')
B = sqlContext.read.csv('s3://my_bucket.s3.amazonaws.com:443/path/within/bucket/file_blob', schema=StructType([ StructField('b', IntegerType, False),
    StructField('bb', IntegerType, False),
    StructField('bbb', IntegerType, False),
    StructField('column', BooleanType, False),
    StructField('another_column', BooleanType, False),
    StructField('yet_another_column', BooleanType, False) ])
, sep=',')
C = FILTER A BY A.a == 3 AND (A.aa >= 0 OR A.aaa < -100);
D = FILTER B BY B.b != 'Bebe' OR B.bb == 'Zeze';
# quoted source code: start
X = LOAD 'data' AS (a1:int,a2:int,a3:int);
DUMP X;
Y = FILTER X BY a3 == 3;

STORE X INTO 'db://db_connection_string';
STORE Y INTO 'output' USING PigDump();
# quoted source code: finish
sqlContext.write.csv('s3://my_bucket.s3.amazonaws.com:443/path/within/bucket/table_name_c', compression='SNAPPY', sep=',')
sqlContext.write.csv('s3://my_bucket.s3.amazonaws.com:443/path/within/bucket/table_name_d', compression='SNAPPY', sep=',')
# SDPL output: EOF
